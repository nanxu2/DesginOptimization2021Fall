{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-logging",
   "metadata": {},
   "source": [
    "### Problem 1 (50 points) \n",
    "\n",
    "Vapor-liquid equilibria data are correlated using two adjustable parameters $A_{12}$ and $A_{21}$ per binary\n",
    "mixture. For low pressures, the equilibrium relation can be formulated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p = & x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{water}^{sat}\\\\\n",
    "& + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{1,4 dioxane}^{sat}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here the saturation pressures are given by the Antoine equation\n",
    "\n",
    "$$\n",
    "\\log_{10}(p^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$$\n",
    "\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane\n",
    "system is given below.\n",
    "\n",
    "|             | $a_1$     | $a_2$      | $a_3$     |\n",
    "|:------------|:--------|:---------|:--------|\n",
    "| Water       | 8.07131 | 1730.63  | 233.426 |\n",
    "| 1,4 dioxane | 7.43155 | 1554.679 | 240.337 |\n",
    "\n",
    "\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$.\n",
    "\n",
    "|$x_1$ | 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
    "|:-----|:--------|:---------|:--------|:-----|:-----|:-----|:-----|:-----|:-----|:-----|:-----|\n",
    "|$p$| 28.1 | 34.4 | 36.7 | 36.9 | 36.8 | 36.7 | 36.5 | 35.4 | 32.9 | 27.7 | 17.5 |\n",
    "\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table: \n",
    "\n",
    "1. Formulate the least square problem; \n",
    "2. Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1; \n",
    "3. Compare your optimized model with the data. Does your model fit well with the data?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1\n",
    "The objective function is following:<br />\n",
    "$min_{A_{12},A_{21}}\\Sigma_{i=1}^{n}(p(x^{(i), A_{12}, A_{21}})-p^{(i)})^2$ <br />\n",
    "where $n = 11$,  $x_2=1-x_1$<br />\n",
    "$p(x^{(i)}, A_{12},A_{21})=x_1^{(i)}exp(A_{12}(\\frac{A_{21}x_2^{(i)}}{A_{12}x^{(i)}_1+A_{21}x_2^{(i)}})^2)p_{water}^{sat}+x_2^{(i)}exp(A_{12}(\\frac{A_{21}x_1^{(i)}}{A_{12}x^{(i)}_1+A_{21}x_2^{(i)}})^2)p_{1,4dioxane}^{sat}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3188082971.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/tmp/ipykernel_6243/3188082971.py\"\u001B[0;36m, line \u001B[0;32m2\u001B[0m\n\u001B[0;31m    The objective function is following\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A12 and A21 is [1.9545084 1.6900573], respectly, with loss 0.7166754603385925\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "pwater_sat = np.power(10, (8.071 - 1730.63/(20 + 233.426)))\n",
    "p14_sat = np.power(10, (7.432 - 1554.68/(20 + 240.337)))\n",
    "x = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "p = [28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5]\n",
    "\n",
    "def pressure(a, xi):\n",
    "\n",
    "    x1 = xi\n",
    "    x2 = 1 - x1\n",
    "    A12 = a[0]\n",
    "    A21 = a[1]\n",
    "    p_n = x1 * t.exp(A12* ( (A21*x2)/(A12*x1 + A21*x2) )**2 ) * pwater_sat + x2 * t.exp(A21* ( (A12*x1)/(A12*x1 + A21*x2) )**2 ) * p14_sat\n",
    "    return p_n\n",
    "\n",
    "def object_fun(a):\n",
    "\n",
    "    loss_ = 0\n",
    "    n = len(x)\n",
    "\n",
    "    for i in range(n):\n",
    "        xi = x[i]\n",
    "        p_n = pressure(a, xi)\n",
    "        loss_ = loss_ + (p_n - p[i])**2  # Sum the squared difference.\n",
    "\n",
    "    return loss_\n",
    "\n",
    "def linesearch(a):\n",
    "\n",
    "    step = 0.1\n",
    "    while object_fun(a - step*a.grad) > object_fun(a)-step*(0.5)*np.matmul(a.grad, a.grad):\n",
    "        step = 0.5 * step\n",
    "\n",
    "    return step\n",
    "\n",
    "a = Variable(t.tensor([1.0, 1.0]), requires_grad=True)\n",
    "diff = 100\n",
    "\n",
    "while diff > 0.1:\n",
    "\n",
    "    obj = object_fun(a)\n",
    "    obj.backward()\n",
    "    step = linesearch(a)\n",
    "    diff = t.linalg.norm(a.grad)\n",
    "\n",
    "    with t.no_grad():\n",
    "        a -= step * a.grad\n",
    "        a.grad.zero_()\n",
    "\n",
    "print('A12 and A21 is {}, respectly, with loss {}'.format(a.data.numpy(), obj.data.numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pressures   Model Pressures\n",
      "The true pressure is 28.1, and the model pressure is 28.85372543334961\n",
      "The true pressure is 34.4, and the model pressure is 34.645721435546875\n",
      "The true pressure is 36.7, and the model pressure is 36.45185852050781\n",
      "The true pressure is 36.9, and the model pressure is 36.866844177246094\n",
      "The true pressure is 36.8, and the model pressure is 36.873008728027344\n",
      "The true pressure is 36.7, and the model pressure is 36.747642517089844\n",
      "The true pressure is 36.5, and the model pressure is 36.38789367675781\n",
      "The true pressure is 35.4, and the model pressure is 35.38384246826172\n",
      "The true pressure is 32.9, and the model pressure is 32.949913024902344\n",
      "The true pressure is 27.7, and the model pressure is 27.73257064819336\n",
      "The true pressure is 17.5, and the model pressure is 17.460784912109375\n",
      "The mean squared error of the predicted data w.r.t true values is 0.06515213753043846\n"
     ]
    }
   ],
   "source": [
    "a_ = a.data\n",
    "print('True Pressures   Model Pressures')\n",
    "y_pred = np.zeros([len(x), 1])\n",
    "for i in range(len(x)):\n",
    "    y_pred[i] = pressure(a_, x[i])\n",
    "    print('The true pressure is {}, and the model pressure is {}'.format(p[i], pressure(a, x[i])))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "err = mean_squared_error(p, y_pred)\n",
    "print('The mean squared error of the predicted data w.r.t true values is {}'.format(err))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the means squared error is 0.065, the model-predicted pressures fit very well with the data.\n",
    "### Problem 2 (50 points)\n",
    "Solve the following problem using Bayesian Optimization:\n",
    "$$\n",
    "    \\min_{x_1, x_2} \\quad \\left(4-2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2,\n",
    "$$\n",
    "for $x_1 \\in [-3,3]$ and $x_2 \\in [-2,2]$. A tutorial on Bayesian Optimization can be found [here](https://thuijskens.github.io/2016/12/29/bayesian-optimisation/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divine-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0., -4.], dtype=float32)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple example of using PyTorch for gradient descent\n",
    "\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Define a variable, make sure requires_grad=True so that PyTorch can take gradient with respect to this variable\n",
    "x = Variable(t.tensor([1.0, 0.0]), requires_grad=True)\n",
    "\n",
    "# Define a loss\n",
    "loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "\n",
    "# Take gradient\n",
    "loss.backward()\n",
    "\n",
    "# Check the gradient. numpy() turns the variable from a PyTorch tensor to a numpy array.\n",
    "x.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "positive-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2., -6.], dtype=float32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's examine the gradient at a different x.\n",
    "x.data = t.tensor([2.0, 1.0])\n",
    "loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "loss.backward()\n",
    "x.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infectious-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.9999971]\n",
      "8.185452e-12\n"
     ]
    }
   ],
   "source": [
    "# Here is a code for gradient descent without line search\n",
    "\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(t.tensor([1.0, 0.0]), requires_grad=True)\n",
    "\n",
    "# Fix the step size\n",
    "a = 0.01\n",
    "\n",
    "# Start gradient descent\n",
    "for i in range(1000):  # TODO: change the termination criterion\n",
    "    loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "    loss.backward()\n",
    "    \n",
    "    # no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\n",
    "    with t.no_grad():\n",
    "        x -= a * x.grad\n",
    "        \n",
    "        # need to clear the gradient at every step, or otherwise it will accumulate...\n",
    "        x.grad.zero_()\n",
    "        \n",
    "print(x.data.numpy())\n",
    "print(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painful-climb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}