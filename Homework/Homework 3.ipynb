{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-logging",
   "metadata": {},
   "source": [
    "### Problem 1 (50 points) \n",
    "\n",
    "Vapor-liquid equilibria data are correlated using two adjustable parameters $A_{12}$ and $A_{21}$ per binary\n",
    "mixture. For low pressures, the equilibrium relation can be formulated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p = & x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{water}^{sat}\\\\\n",
    "& + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{1,4 dioxane}^{sat}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here the saturation pressures are given by the Antoine equation\n",
    "\n",
    "$$\n",
    "\\log_{10}(p^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$$\n",
    "\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane\n",
    "system is given below.\n",
    "\n",
    "|             | $a_1$     | $a_2$      | $a_3$     |\n",
    "|:------------|:--------|:---------|:--------|\n",
    "| Water       | 8.07131 | 1730.63  | 233.426 |\n",
    "| 1,4 dioxane | 7.43155 | 1554.679 | 240.337 |\n",
    "\n",
    "\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$.\n",
    "\n",
    "|$x_1$ | 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
    "|:-----|:--------|:---------|:--------|:-----|:-----|:-----|:-----|:-----|:-----|:-----|:-----|\n",
    "|$p$| 28.1 | 34.4 | 36.7 | 36.9 | 36.8 | 36.7 | 36.5 | 35.4 | 32.9 | 27.7 | 17.5 |\n",
    "\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table: \n",
    "\n",
    "1. Formulate the least square problem; \n",
    "2. Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1; \n",
    "3. Compare your optimized model with the data. Does your model fit well with the data?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1\n",
    "The objective function is following:<br />\n",
    "$min_{A_{12},A_{21}}\\Sigma_{i=1}^{n}(p(x^{(i), A_{12}, A_{21}})-p^{(i)})^2$ <br />\n",
    "where $n = 11$,  $x_2=1-x_1$<br />\n",
    "$p(x^{(i)}, A_{12},A_{21})=x_1^{(i)}exp(A_{12}(\\frac{A_{21}x_2^{(i)}}{A_{12}x^{(i)}_1+A_{21}x_2^{(i)}})^2)p_{water}^{sat}+x_2^{(i)}exp(A_{12}(\\frac{A_{21}x_1^{(i)}}{A_{12}x^{(i)}_1+A_{21}x_2^{(i)}})^2)p_{1,4dioxane}^{sat}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3188082971.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/tmp/ipykernel_6243/3188082971.py\"\u001B[0;36m, line \u001B[0;32m2\u001B[0m\n\u001B[0;31m    The objective function is following\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A12 and A21 is [1.9545084 1.6900573], respectly, with loss 0.7166754603385925\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "pwater_sat = np.power(10, (8.071 - 1730.63/(20 + 233.426)))\n",
    "p14_sat = np.power(10, (7.432 - 1554.68/(20 + 240.337)))\n",
    "x = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "p = [28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5]\n",
    "\n",
    "def pressure(a, xi):\n",
    "\n",
    "    x1 = xi\n",
    "    x2 = 1 - x1\n",
    "    A12 = a[0]\n",
    "    A21 = a[1]\n",
    "    p_n = x1 * t.exp(A12* ( (A21*x2)/(A12*x1 + A21*x2) )**2 ) * pwater_sat + x2 * t.exp(A21* ( (A12*x1)/(A12*x1 + A21*x2) )**2 ) * p14_sat\n",
    "    return p_n\n",
    "\n",
    "def object_fun(a):\n",
    "\n",
    "    loss_ = 0\n",
    "    n = len(x)\n",
    "\n",
    "    for i in range(n):\n",
    "        xi = x[i]\n",
    "        p_n = pressure(a, xi)\n",
    "        loss_ = loss_ + (p_n - p[i])**2\n",
    "\n",
    "    return loss_\n",
    "\n",
    "def linesearch(a):\n",
    "\n",
    "    step = 0.1\n",
    "    while object_fun(a - step*a.grad) > object_fun(a)-step*(0.5)*np.matmul(a.grad, a.grad):\n",
    "        step = 0.5 * step\n",
    "\n",
    "    return step\n",
    "\n",
    "a = Variable(t.tensor([1.0, 1.0]), requires_grad=True)\n",
    "diff = 100\n",
    "\n",
    "while diff > 0.1:\n",
    "\n",
    "    obj = object_fun(a)\n",
    "    obj.backward()\n",
    "    step = linesearch(a)\n",
    "    diff = t.linalg.norm(a.grad)\n",
    "\n",
    "    with t.no_grad():\n",
    "        a -= step * a.grad\n",
    "        a.grad.zero_()\n",
    "\n",
    "print('A12 and A21 is {}, respectly, with loss {}'.format(a.data.numpy(), obj.data.numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pressures   Model Pressures\n",
      "The true pressure is 28.1, and the model pressure is 28.85372543334961\n",
      "The true pressure is 34.4, and the model pressure is 34.645721435546875\n",
      "The true pressure is 36.7, and the model pressure is 36.45185852050781\n",
      "The true pressure is 36.9, and the model pressure is 36.866844177246094\n",
      "The true pressure is 36.8, and the model pressure is 36.873008728027344\n",
      "The true pressure is 36.7, and the model pressure is 36.747642517089844\n",
      "The true pressure is 36.5, and the model pressure is 36.38789367675781\n",
      "The true pressure is 35.4, and the model pressure is 35.38384246826172\n",
      "The true pressure is 32.9, and the model pressure is 32.949913024902344\n",
      "The true pressure is 27.7, and the model pressure is 27.73257064819336\n",
      "The true pressure is 17.5, and the model pressure is 17.460784912109375\n",
      "The mean squared error of the predicted data w.r.t true values is 0.06515213753043846\n"
     ]
    }
   ],
   "source": [
    "a_ = a.data\n",
    "print('True Pressures   Model Pressures')\n",
    "y_pred = np.zeros([len(x), 1])\n",
    "for i in range(len(x)):\n",
    "    y_pred[i] = pressure(a_, x[i])\n",
    "    print('The true pressure is {}, and the model pressure is {}'.format(p[i], pressure(a, x[i])))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "err = mean_squared_error(p, y_pred)\n",
    "print('The mean squared error of the predicted data w.r.t true values is {}'.format(err))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the means squared error is 0.065, the model-predicted pressures fit very well with the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 2 (50 points)\n",
    "Solve the following problem using Bayesian Optimization:\n",
    "$$\\min_{x_1, x_2} \\quad \\left(4-2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2,$$\n",
    "for $x_1 \\in [-3,3]$ and $x_2 \\in [-2,2]$. A tutorial on Bayesian Optimization can be found [here](https://thuijskens.github.io/2016/12/29/bayesian-optimisation/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divine-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import gaussian_process as gp\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def object_fun(x):\n",
    "    v = ((4 - (2.1*(x[0]**2)) + ((x[0]**4)/3))*(x[0]**2)) + (x[0]*x[1]) + ((-4 + 4*x[1]**2)*x[1]**2)\n",
    "    return v\n",
    "\n",
    "def expected_improvement(x, model, evaluated_loss, greater_is_better=False, n_params=1):\n",
    "\n",
    "    x_to_predict = x.reshape(-1, n_params)\n",
    "    mu, sigma = model.predict(x_to_predict, return_std=True)\n",
    "\n",
    "    if greater_is_better:\n",
    "        loss_optimum = np.max(evaluated_loss)\n",
    "    else:\n",
    "        loss_optimum = np.min(evaluated_loss)\n",
    "\n",
    "    scaling_factor = (-1) ** (not greater_is_better)\n",
    "\n",
    "    with np.errstate(divide='ignore'):\n",
    "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
    "        expected_improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        expected_improvement[sigma == 0.0] == 0.0\n",
    "\n",
    "    return -1 * expected_improvement\n",
    "\n",
    "\n",
    "def sample_next_hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
    "                               bounds=(0, 10), n_restarts=25):\n",
    "\n",
    "    best_x = None\n",
    "    best_acquisition_value = 1\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
    "\n",
    "        res = minimize(fun=acquisition_func,\n",
    "                       x0=starting_point.reshape(1, -1),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
    "\n",
    "        if res.fun < best_acquisition_value:\n",
    "            best_acquisition_value = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "\n",
    "def bayesian_optimisation(n_iters, sample_loss, bounds, x0=None, n_pre_samples=5,\n",
    "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7):\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    if x0 is None:\n",
    "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "    else:\n",
    "        for params in x0:\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "\n",
    "    xp = np.array(x_list)\n",
    "    yp = np.array(y_list)\n",
    "\n",
    "    if gp_params is not None:\n",
    "        model = gp.GaussianProcessRegressor(**gp_params)\n",
    "    else:\n",
    "        kernel = gp.kernels.Matern()\n",
    "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                            alpha=alpha,\n",
    "                                            n_restarts_optimizer=10,\n",
    "                                            normalize_y=True)\n",
    "\n",
    "    for n in range(n_iters):\n",
    "\n",
    "        model.fit(xp, yp)\n",
    "\n",
    "        if random_search:\n",
    "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
    "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
    "            next_sample = x_random[np.argmax(ei), :]\n",
    "        else:\n",
    "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
    "\n",
    "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
    "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
    "\n",
    "        cv_score = sample_loss(next_sample)\n",
    "\n",
    "        x_list.append(next_sample)\n",
    "        y_list.append(cv_score)\n",
    "\n",
    "        xp = np.array(x_list)\n",
    "        yp = np.array(y_list)\n",
    "\n",
    "    return xp, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "painful-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value of -1.02614400718987 is at [-0.06122449  0.69387755] \n",
      "For Bayesian Optimization with 100 iteration, the minimum value of -1.002744475669542 is at [-0.14689115  0.67015273]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x_1 = np.linspace(-3,3)\n",
    "x_2 = np.linspace(-2,2)\n",
    "param_grid = np.array([[x_1i, x_2i] for x_1i in x_1 for x_2i in x_2])\n",
    "real_loss = [object_fun(params) for params in param_grid]\n",
    "print('The minimum value of {} is at {} '.format(np.amin(real_loss), param_grid[np.array(real_loss).argmin(), :]))\n",
    "\n",
    "bounds = np.array([[-3, 3], [-2, 2]])\n",
    "xp, yp = bayesian_optimisation(n_iters=100,\n",
    "                               sample_loss=object_fun,\n",
    "                               bounds=bounds,\n",
    "                               n_pre_samples=3,\n",
    "                               random_search=100000)\n",
    "\n",
    "print('For Bayesian Optimization with 100 iteration, the minimum value of {} is at {}'.format(np.amin(yp), xp[np.where(yp == np.amin(yp))[0][0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}